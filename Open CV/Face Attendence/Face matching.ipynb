{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Face Attendence(Hough Transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872f5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd704419",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a235f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "personName=[]\n",
    "encodeList=[]\n",
    "myList=os.listdir(path)\n",
    "for i in myList:\n",
    "    ci=cv2.imread(f'{path}/{i}')\n",
    "    images.append(ci)\n",
    "    personName.append(os.path.splitext(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e8abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face encoding(using Hough algorith)\n",
    "def faceEncoding(images):\n",
    "    for img in images:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        encode=face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "encodeListKnown=encodeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38e29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attendance(name):\n",
    "    with open('Attend.cvs', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            time_now = datetime.now()\n",
    "            tStr = time_now.strftime('%H:%M:%S')\n",
    "            dStr = time_now.strftime('%d/%m/%Y')\n",
    "            f.writelines(f'\\n{name},{tStr},{dStr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    faces=cv2.resize(frame,(0,0),None,0.25,0.25)\n",
    "    face=cv2.cvtColor(faces,cv2.COLOR_BGR2RGB)\n",
    "    facesCurrentFrame=face_recognition.face_locations(faces)\n",
    "    encodeCurrentFrame=face_recognition.face_encodings(faces,facesCurrentFrame)\n",
    "    for encodeFace,faceLoc in zip(encodeCurrentFrame,facesCurrentFrame):\n",
    "        matches=face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        face_distance=face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        \n",
    "        matchIndex=np.argmin(face_distance)\n",
    "        if matches[matchIndex]:\n",
    "            name=personName[matchIndex].upper()\n",
    "            print(name)\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "            cv2.putText(frame,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            attendance(name)\n",
    "    cv2.imshow('Frame',frame)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e7199cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhishek', 'bill gates', 'donald trump', 'elon musk', 'Geeta Devi', 'jeff bezos', 'obama', 'Ravindra', 'Shivani']\n"
     ]
    }
   ],
   "source": [
    "print(personName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226ee53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17cb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b71f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    }
   ],
   "source": [
    "matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            name = personNames[matchIndex].upper()\n",
    "            # print(name)\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            attendance(name)\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cdaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fa632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ba490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhishek.jpg', 'bill gates.jpg', 'donald trump.jpg', 'elon musk.jpg', 'Geeta Devi.jpg', 'jeff bezos.jpg', 'Kajal.jpeg', 'obama.jpg', 'Ravindra.jpg', 'Shivani.jpg']\n",
      "['Abhishek', 'bill gates', 'donald trump', 'elon musk', 'Geeta Devi', 'jeff bezos', 'Kajal', 'obama', 'Ravindra', 'Shivani']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "path = 'images'\n",
    "images = []\n",
    "personNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)\n",
    "for cu_img in myList:\n",
    "    current_Img = cv2.imread(f'{path}/{cu_img}')\n",
    "    images.append(current_Img)\n",
    "    personNames.append(os.path.splitext(cu_img)[0])\n",
    "print(personNames)\n",
    "\n",
    "\n",
    "def faceEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "\n",
    "def attendance(name):\n",
    "    with open('Attendance.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            time_now = datetime.now()\n",
    "            tStr = time_now.strftime('%H:%M:%S')\n",
    "            dStr = time_now.strftime('%d/%m/%Y')\n",
    "            f.writelines(f'\\n{name},{tStr},{dStr}')\n",
    "\n",
    "\n",
    "encodeListKnown = faceEncodings(images)\n",
    "print('All Encodings Complete!!!')\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    faces=cv2.resize(frame,(500,500))\n",
    "    faces = cv2.cvtColor(faces, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    facesCurrentFrame = face_recognition.face_locations(faces)\n",
    "    encodesCurrentFrame = face_recognition.face_encodings(faces, facesCurrentFrame)\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodesCurrentFrame, facesCurrentFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        # print(faceDis)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            name = personNames[matchIndex].upper()\n",
    "            # print(name)\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            attendance(name)\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa6b6ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Open CV\\\\Face Attendence'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='C:\\\\Users\\\\user\\\\Desktop\\\\Open CV\\\\Face Attendence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320d408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a18d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77b4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45870f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594fe63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d5bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb8b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ca797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ecec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9e03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f8bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19bddc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import image\n",
    "imgElon=face_recognition.load_image_file('el.jpg')\n",
    "#imgElon=cv2.resize(imgElon,(600,600))\n",
    "#converting into RGB from BGR\n",
    "imgElon=cv2.cvtColor(imgElon,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#import test image\n",
    "imgtest=face_recognition.load_image_file('test.jpg')\n",
    "#converting into RGB from BGR\n",
    "imgtest=cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9556436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "481e0c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[235, 155,  38],\n",
       "        [235, 152,  36],\n",
       "        [232, 149,  33],\n",
       "        ...,\n",
       "        [ 10,   0,   0],\n",
       "        [ 10,   0,   0],\n",
       "        [ 10,   0,   0]],\n",
       "\n",
       "       [[237, 156,  41],\n",
       "        [236, 155,  40],\n",
       "        [233, 152,  37],\n",
       "        ...,\n",
       "        [ 10,   0,   0],\n",
       "        [ 10,   0,   0],\n",
       "        [ 10,   0,   0]],\n",
       "\n",
       "       [[240, 159,  48],\n",
       "        [239, 158,  47],\n",
       "        [237, 157,  44],\n",
       "        ...,\n",
       "        [ 10,   0,   0],\n",
       "        [ 10,   0,   0],\n",
       "        [ 10,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[201, 153, 129],\n",
       "        [201, 153, 129],\n",
       "        [202, 154, 130],\n",
       "        ...,\n",
       "        [ 21,   0,   2],\n",
       "        [ 21,   0,   2],\n",
       "        [ 21,   0,   2]],\n",
       "\n",
       "       [[201, 153, 129],\n",
       "        [201, 153, 129],\n",
       "        [201, 153, 129],\n",
       "        ...,\n",
       "        [ 21,   0,   2],\n",
       "        [ 21,   0,   2],\n",
       "        [ 21,   0,   2]],\n",
       "\n",
       "       [[201, 153, 129],\n",
       "        [201, 153, 129],\n",
       "        [201, 153, 129],\n",
       "        ...,\n",
       "        [ 21,   1,   0],\n",
       "        [ 21,   1,   0],\n",
       "        [ 21,   1,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceloc=face_recognition.face_locations(imgElon)[0]\n",
    "encodeElon=face_recognition.face_encodings(imgElon)[0]\n",
    "cv2.rectangle(imgElon,(faceloc[3],faceloc[0],faceloc[1],faceloc[2]),(255,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e74bd701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 397, 196, 268)\n"
     ]
    }
   ],
   "source": [
    "print(faceloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3c8ec2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.imshow('Frame',imgElon)\n",
    "cv2.imshow('Frame',imgtest)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbebc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df40ce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3,  2,  8],\n",
       "        [ 3,  2,  8],\n",
       "        [ 3,  2,  8],\n",
       "        ...,\n",
       "        [ 1,  1,  3],\n",
       "        [ 1,  1,  3],\n",
       "        [ 1,  1,  3]],\n",
       "\n",
       "       [[ 3,  2,  8],\n",
       "        [ 3,  2,  8],\n",
       "        [ 3,  2,  8],\n",
       "        ...,\n",
       "        [ 1,  1,  3],\n",
       "        [ 1,  1,  3],\n",
       "        [ 1,  1,  3]],\n",
       "\n",
       "       [[ 3,  2,  8],\n",
       "        [ 3,  2,  8],\n",
       "        [ 3,  2,  8],\n",
       "        ...,\n",
       "        [ 1,  1,  3],\n",
       "        [ 1,  1,  3],\n",
       "        [ 1,  1,  3]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3,  6, 11],\n",
       "        [ 3,  6, 13],\n",
       "        [ 3,  6, 13],\n",
       "        ...,\n",
       "        [ 2,  2, 12],\n",
       "        [ 2,  2, 12],\n",
       "        [ 2,  2, 12]],\n",
       "\n",
       "       [[ 3,  6, 11],\n",
       "        [ 3,  6, 13],\n",
       "        [ 3,  6, 13],\n",
       "        ...,\n",
       "        [ 2,  2, 12],\n",
       "        [ 2,  2, 12],\n",
       "        [ 2,  2, 12]],\n",
       "\n",
       "       [[ 3,  6, 11],\n",
       "        [ 3,  6, 13],\n",
       "        [ 3,  6, 13],\n",
       "        ...,\n",
       "        [ 2,  2, 12],\n",
       "        [ 2,  2, 12],\n",
       "        [ 2,  2, 12]]], dtype=uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facetest=face_recognition.face_locations(imgtest)[0]\n",
    "encodetest=face_recognition.face_encodings(imgtest)[0]\n",
    "cv2.rectangle(imgtest,(facetest[3],facetest[0],facetest[1],facetest[2]),(255,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c6617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd630d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cf86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfe4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa08740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c813e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bda2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41412f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c85ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc18d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc0423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3412b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2db93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925d0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d34cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf33d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0250d4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577b670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc47471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523cd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde47f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c31d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df930712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
